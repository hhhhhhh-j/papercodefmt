_current_progress_remaining:
    value: 1
_custom_logger:
    value: "False"
_episode_num:
    value: 0
_last_episode_starts:
    value: '[ True]'
_last_obs:
    value: |-
        OrderedDict({'global_map': array([[[[0., 0., 0., ..., 0., 0., 0.],
                 [0., 0., 0., ..., 0., 0., 0.],
                 [0., 0., 0., ..., 0., 0., 0.],
                 ...,
                 [0., 0., 0., ..., 0., 0., 0.],
                 [0., 0., 0., ..., 0., 0., 0.],
                 [0., 0., 0., ..., 0., 0., 0.]],

                [[0., 0., 0., ..., 0., 0., 0.],
                 [0., 0., 0., ..., 0., 0., 0.],
                 [0., 0., 0., ..., 0., 0., 0.],
                 ...,
                 [0., 0., 0., ..., 0., 0., 0.],
                 [0., 0., 0., ..., 0., 0., 0.],
                 [0., 0., 0., ..., 0., 0., 0.]],

                [[0., 0., 0., ..., 0., 0., 0.],
                 [0., 0., 0., ..., 0., 0., 0.],
                 [0., 0., 0., ..., 0., 0., 0.],
                 ...,
                 [0., 0., 0., ..., 0., 0., 0.],
                 [0., 0., 0., ..., 0., 0., 0.],
                 [0., 0., 0., ..., 0., 0., 0.]],

                [[1., 1., 1., ..., 1., 1., 1.],
                 [1., 1., 1., ..., 1., 1., 1.],
                 [1., 1., 1., ..., 1., 1., 1.],
                 ...,
                 [1., 1., 1., ..., 1., 1., 1.],
                 [1., 1., 1., ..., 1., 1., 1.],
                 [1., 1., 1., ..., 1., 1., 1.]]]],
              shape=(1, 4, 256, 256), dtype=float32), 'local_map': array([[[[0., 0., 0., ..., 0., 0., 0.],
                 [0., 0., 0., ..., 0., 0., 0.],
                 [0., 0., 0., ..., 0., 0., 0.],
                 ...,
                 [0., 0., 0., ..., 0., 0., 0.],
                 [0., 0., 0., ..., 0., 0., 0.],
                 [0., 0., 0., ..., 0., 0., 0.]],

                [[0., 0., 0., ..., 0., 0., 0.],
                 [0., 0., 0., ..., 0., 0., 0.],
                 [0., 0., 0., ..., 0., 0., 0.],
                 ...,
                 [0., 0., 0., ..., 0., 0., 0.],
                 [0., 0., 0., ..., 0., 0., 0.],
                 [0., 0., 0., ..., 0., 0., 0.]],

                [[0., 0., 0., ..., 0., 0., 0.],
                 [0., 0., 0., ..., 0., 0., 0.],
                 [0., 0., 0., ..., 0., 0., 0.],
                 ...,
                 [0., 0., 0., ..., 0., 0., 0.],
                 [0., 0., 0., ..., 0., 0., 0.],
                 [0., 0., 0., ..., 0., 0., 0.]],

                [[1., 1., 1., ..., 1., 1., 1.],
                 [1., 1., 1., ..., 1., 1., 1.],
                 [1., 1., 1., ..., 1., 1., 1.],
                 ...,
                 [1., 1., 1., ..., 1., 1., 1.],
                 [1., 1., 1., ..., 1., 1., 1.],
                 [1., 1., 1., ..., 1., 1., 1.]]]],
              shape=(1, 4, 64, 64), dtype=float32), 'pose': array([[0.734375  , 0.5390625 , 0.00214855, 0.9999977 , 0.1570536 ,
                0.13255653]], dtype=float32)})
_last_original_obs:
    value: None
_logger:
    value: <stable_baselines3.common.logger.Logger object at 0x7f3e74fafd40>
_n_updates:
    value: 0
_num_timesteps_at_start:
    value: 0
_stats_window_size:
    value: 100
_total_timesteps:
    value: 1000000
_vec_normalize_env:
    value: None
_wandb:
    value:
        cli_version: 0.23.1
        e:
            x6smd4uz24g8ba06pizz3wkd8cri6676:
                codePath: scripts/Train_Script.py
                codePathLocal: scripts/Train_Script.py
                cpu_count: 8
                cpu_count_logical: 16
                cudaVersion: "12.8"
                disk:
                    /:
                        total: "180902232064"
                        used: "86711214080"
                email: 3297240254@qq.com
                executable: /home/fmt/miniconda3/envs/sb3/bin/python
                git:
                    commit: e2f8869d0f7b8f0f479fb96844b8ac39118af31f
                gpu: NVIDIA GeForce GTX 1650
                gpu_count: 1
                gpu_nvidia:
                    - architecture: Turing
                      cudaCores: 896
                      memoryTotal: "4294967296"
                      name: NVIDIA GeForce GTX 1650
                      uuid: GPU-866177ef-22d3-fdee-6758-f45e9f57a01c
                host: fmt-Lenovo-Legion-Y7000P2020
                memory:
                    total: "16623517696"
                os: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
                program: /home/fmt/catkin_ws/src/fmt_/sb3_SAC/scripts/Train_Script.py
                python: CPython 3.12.12
                root: ./
                startedAt: "2026-01-26T06:40:38.355838Z"
                writerId: x6smd4uz24g8ba06pizz3wkd8cri6676
        m: []
        python_version: 3.12.12
        t:
            "1":
                - 1
            "2":
                - 1
            "3":
                - 13
                - 16
                - 22
                - 35
            "4": 3.12.12
            "5": 0.23.1
            "12": 0.23.1
            "13": linux-x86_64
action_noise:
    value: None
action_space:
    value: Box(-1.0, 1.0, (3,), float32)
actor:
    value: |-
        Actor(
          (features_extractor): CustomEncoder(
            (cnn_global): Sequential(
              (0): Conv2d(4, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)
              (1): GroupNorm(8, 16, eps=1e-05, affine=True)
              (2): ReLU()
              (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (4): GroupNorm(8, 32, eps=1e-05, affine=True)
              (5): ReLU()
              (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (7): GroupNorm(8, 64, eps=1e-05, affine=True)
              (8): ReLU()
              (9): AdaptiveAvgPool2d(output_size=(1, 1))
              (10): Flatten(start_dim=1, end_dim=-1)
            )
            (cnn_local): Sequential(
              (0): Conv2d(4, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)
              (1): GroupNorm(8, 16, eps=1e-05, affine=True)
              (2): ReLU()
              (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (4): GroupNorm(8, 32, eps=1e-05, affine=True)
              (5): ReLU()
              (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (7): GroupNorm(8, 64, eps=1e-05, affine=True)
              (8): ReLU()
              (9): AdaptiveAvgPool2d(output_size=(1, 1))
              (10): Flatten(start_dim=1, end_dim=-1)
            )
            (pose_mlp): Sequential(
              (0): Linear(in_features=6, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): ReLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): ReLU()
            )
            (fuse): Sequential(
              (0): Linear(in_features=192, out_features=256, bias=True)
              (1): ReLU()
              (2): Linear(in_features=256, out_features=256, bias=True)
              (3): ReLU()
            )
          )
          (latent_pi): Sequential(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): ReLU()
            (2): Linear(in_features=256, out_features=256, bias=True)
            (3): ReLU()
          )
          (mu): Linear(in_features=256, out_features=3, bias=True)
          (log_std): Linear(in_features=256, out_features=3, bias=True)
        )
algo:
    value: SAC
batch_norm_stats:
    value: '[]'
batch_norm_stats_target:
    value: '[]'
batch_size:
    value: 32
buffer_size:
    value: 10000
critic:
    value: |-
        ContinuousCritic(
          (features_extractor): CustomEncoder(
            (cnn_global): Sequential(
              (0): Conv2d(4, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)
              (1): GroupNorm(8, 16, eps=1e-05, affine=True)
              (2): ReLU()
              (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (4): GroupNorm(8, 32, eps=1e-05, affine=True)
              (5): ReLU()
              (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (7): GroupNorm(8, 64, eps=1e-05, affine=True)
              (8): ReLU()
              (9): AdaptiveAvgPool2d(output_size=(1, 1))
              (10): Flatten(start_dim=1, end_dim=-1)
            )
            (cnn_local): Sequential(
              (0): Conv2d(4, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)
              (1): GroupNorm(8, 16, eps=1e-05, affine=True)
              (2): ReLU()
              (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (4): GroupNorm(8, 32, eps=1e-05, affine=True)
              (5): ReLU()
              (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (7): GroupNorm(8, 64, eps=1e-05, affine=True)
              (8): ReLU()
              (9): AdaptiveAvgPool2d(output_size=(1, 1))
              (10): Flatten(start_dim=1, end_dim=-1)
            )
            (pose_mlp): Sequential(
              (0): Linear(in_features=6, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): ReLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): ReLU()
            )
            (fuse): Sequential(
              (0): Linear(in_features=192, out_features=256, bias=True)
              (1): ReLU()
              (2): Linear(in_features=256, out_features=256, bias=True)
              (3): ReLU()
            )
          )
          (qf0): Sequential(
            (0): Linear(in_features=259, out_features=256, bias=True)
            (1): ReLU()
            (2): Linear(in_features=256, out_features=256, bias=True)
            (3): ReLU()
            (4): Linear(in_features=256, out_features=1, bias=True)
          )
          (qf1): Sequential(
            (0): Linear(in_features=259, out_features=256, bias=True)
            (1): ReLU()
            (2): Linear(in_features=256, out_features=256, bias=True)
            (3): ReLU()
            (4): Linear(in_features=256, out_features=1, bias=True)
          )
        )
critic_target:
    value: |-
        ContinuousCritic(
          (features_extractor): CustomEncoder(
            (cnn_global): Sequential(
              (0): Conv2d(4, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)
              (1): GroupNorm(8, 16, eps=1e-05, affine=True)
              (2): ReLU()
              (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (4): GroupNorm(8, 32, eps=1e-05, affine=True)
              (5): ReLU()
              (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (7): GroupNorm(8, 64, eps=1e-05, affine=True)
              (8): ReLU()
              (9): AdaptiveAvgPool2d(output_size=(1, 1))
              (10): Flatten(start_dim=1, end_dim=-1)
            )
            (cnn_local): Sequential(
              (0): Conv2d(4, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)
              (1): GroupNorm(8, 16, eps=1e-05, affine=True)
              (2): ReLU()
              (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (4): GroupNorm(8, 32, eps=1e-05, affine=True)
              (5): ReLU()
              (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (7): GroupNorm(8, 64, eps=1e-05, affine=True)
              (8): ReLU()
              (9): AdaptiveAvgPool2d(output_size=(1, 1))
              (10): Flatten(start_dim=1, end_dim=-1)
            )
            (pose_mlp): Sequential(
              (0): Linear(in_features=6, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): ReLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): ReLU()
            )
            (fuse): Sequential(
              (0): Linear(in_features=192, out_features=256, bias=True)
              (1): ReLU()
              (2): Linear(in_features=256, out_features=256, bias=True)
              (3): ReLU()
            )
          )
          (qf0): Sequential(
            (0): Linear(in_features=259, out_features=256, bias=True)
            (1): ReLU()
            (2): Linear(in_features=256, out_features=256, bias=True)
            (3): ReLU()
            (4): Linear(in_features=256, out_features=1, bias=True)
          )
          (qf1): Sequential(
            (0): Linear(in_features=259, out_features=256, bias=True)
            (1): ReLU()
            (2): Linear(in_features=256, out_features=256, bias=True)
            (3): ReLU()
            (4): Linear(in_features=256, out_features=1, bias=True)
          )
        )
device:
    value: cuda
ent_coef:
    value: auto
ent_coef_optimizer:
    value: |-
        Adam (
        Parameter Group 0
            amsgrad: False
            betas: (0.9, 0.999)
            capturable: False
            decoupled_weight_decay: False
            differentiable: False
            eps: 1e-08
            foreach: None
            fused: None
            lr: 0.0003
            maximize: False
            weight_decay: 0
        )
env:
    value: <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f3e63fe9340>
ep_info_buffer:
    value: deque([], maxlen=100)
ep_success_buffer:
    value: deque([], maxlen=100)
features_dim:
    value: 256
gamma:
    value: 0.99
gradient_steps:
    value: 1
learning_rate:
    value: 0.0003
learning_starts:
    value: 100
log_ent_coef:
    value: tensor([0.], device='cuda:0', requires_grad=True)
lr_schedule:
    value: FloatSchedule(ConstantSchedule(val=0.0003))
n_envs:
    value: 1
n_steps:
    value: 1
net_arch:
    value:
        - 256
        - 256
num_timesteps:
    value: 0
observation_space:
    value: 'Dict(''global_map'': Box(0.0, 1.0, (4, 256, 256), float32), ''local_map'': Box(0.0, 1.0, (4, 64, 64), float32), ''pose'': Box(-1.0, 1.0, (6,), float32))'
optimize_memory_usage:
    value: "False"
policy:
    value: |-
        MultiInputPolicy(
          (actor): Actor(
            (features_extractor): CustomEncoder(
              (cnn_global): Sequential(
                (0): Conv2d(4, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)
                (1): GroupNorm(8, 16, eps=1e-05, affine=True)
                (2): ReLU()
                (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (4): GroupNorm(8, 32, eps=1e-05, affine=True)
                (5): ReLU()
                (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (7): GroupNorm(8, 64, eps=1e-05, affine=True)
                (8): ReLU()
                (9): AdaptiveAvgPool2d(output_size=(1, 1))
                (10): Flatten(start_dim=1, end_dim=-1)
              )
              (cnn_local): Sequential(
                (0): Conv2d(4, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)
                (1): GroupNorm(8, 16, eps=1e-05, affine=True)
                (2): ReLU()
                (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (4): GroupNorm(8, 32, eps=1e-05, affine=True)
                (5): ReLU()
                (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (7): GroupNorm(8, 64, eps=1e-05, affine=True)
                (8): ReLU()
                (9): AdaptiveAvgPool2d(output_size=(1, 1))
                (10): Flatten(start_dim=1, end_dim=-1)
              )
              (pose_mlp): Sequential(
                (0): Linear(in_features=6, out_features=64, bias=True)
                (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (2): ReLU()
                (3): Linear(in_features=64, out_features=64, bias=True)
                (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (5): ReLU()
              )
              (fuse): Sequential(
                (0): Linear(in_features=192, out_features=256, bias=True)
                (1): ReLU()
                (2): Linear(in_features=256, out_features=256, bias=True)
                (3): ReLU()
              )
            )
            (latent_pi): Sequential(
              (0): Linear(in_features=256, out_features=256, bias=True)
              (1): ReLU()
              (2): Linear(in_features=256, out_features=256, bias=True)
              (3): ReLU()
            )
            (mu): Linear(in_features=256, out_features=3, bias=True)
            (log_std): Linear(in_features=256, out_features=3, bias=True)
          )
          (critic): ContinuousCritic(
            (features_extractor): CustomEncoder(
              (cnn_global): Sequential(
                (0): Conv2d(4, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)
                (1): GroupNorm(8, 16, eps=1e-05, affine=True)
                (2): ReLU()
                (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (4): GroupNorm(8, 32, eps=1e-05, affine=True)
                (5): ReLU()
                (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (7): GroupNorm(8, 64, eps=1e-05, affine=True)
                (8): ReLU()
                (9): AdaptiveAvgPool2d(output_size=(1, 1))
                (10): Flatten(start_dim=1, end_dim=-1)
              )
              (cnn_local): Sequential(
                (0): Conv2d(4, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)
                (1): GroupNorm(8, 16, eps=1e-05, affine=True)
                (2): ReLU()
                (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (4): GroupNorm(8, 32, eps=1e-05, affine=True)
                (5): ReLU()
                (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (7): GroupNorm(8, 64, eps=1e-05, affine=True)
                (8): ReLU()
                (9): AdaptiveAvgPool2d(output_size=(1, 1))
                (10): Flatten(start_dim=1, end_dim=-1)
              )
              (pose_mlp): Sequential(
                (0): Linear(in_features=6, out_features=64, bias=True)
                (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (2): ReLU()
                (3): Linear(in_features=64, out_features=64, bias=True)
                (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (5): ReLU()
              )
              (fuse): Sequential(
                (0): Linear(in_features=192, out_features=256, bias=True)
                (1): ReLU()
                (2): Linear(in_features=256, out_features=256, bias=True)
                (3): ReLU()
              )
            )
            (qf0): Sequential(
              (0): Linear(in_features=259, out_features=256, bias=True)
              (1): ReLU()
              (2): Linear(in_features=256, out_features=256, bias=True)
              (3): ReLU()
              (4): Linear(in_features=256, out_features=1, bias=True)
            )
            (qf1): Sequential(
              (0): Linear(in_features=259, out_features=256, bias=True)
              (1): ReLU()
              (2): Linear(in_features=256, out_features=256, bias=True)
              (3): ReLU()
              (4): Linear(in_features=256, out_features=1, bias=True)
            )
          )
          (critic_target): ContinuousCritic(
            (features_extractor): CustomEncoder(
              (cnn_global): Sequential(
                (0): Conv2d(4, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)
                (1): GroupNorm(8, 16, eps=1e-05, affine=True)
                (2): ReLU()
                (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (4): GroupNorm(8, 32, eps=1e-05, affine=True)
                (5): ReLU()
                (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (7): GroupNorm(8, 64, eps=1e-05, affine=True)
                (8): ReLU()
                (9): AdaptiveAvgPool2d(output_size=(1, 1))
                (10): Flatten(start_dim=1, end_dim=-1)
              )
              (cnn_local): Sequential(
                (0): Conv2d(4, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)
                (1): GroupNorm(8, 16, eps=1e-05, affine=True)
                (2): ReLU()
                (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (4): GroupNorm(8, 32, eps=1e-05, affine=True)
                (5): ReLU()
                (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (7): GroupNorm(8, 64, eps=1e-05, affine=True)
                (8): ReLU()
                (9): AdaptiveAvgPool2d(output_size=(1, 1))
                (10): Flatten(start_dim=1, end_dim=-1)
              )
              (pose_mlp): Sequential(
                (0): Linear(in_features=6, out_features=64, bias=True)
                (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (2): ReLU()
                (3): Linear(in_features=64, out_features=64, bias=True)
                (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (5): ReLU()
              )
              (fuse): Sequential(
                (0): Linear(in_features=192, out_features=256, bias=True)
                (1): ReLU()
                (2): Linear(in_features=256, out_features=256, bias=True)
                (3): ReLU()
              )
            )
            (qf0): Sequential(
              (0): Linear(in_features=259, out_features=256, bias=True)
              (1): ReLU()
              (2): Linear(in_features=256, out_features=256, bias=True)
              (3): ReLU()
              (4): Linear(in_features=256, out_features=1, bias=True)
            )
            (qf1): Sequential(
              (0): Linear(in_features=259, out_features=256, bias=True)
              (1): ReLU()
              (2): Linear(in_features=256, out_features=256, bias=True)
              (3): ReLU()
              (4): Linear(in_features=256, out_features=1, bias=True)
            )
          )
        )
policy_class:
    value: <class 'stable_baselines3.sac.policies.MultiInputPolicy'>
policy_kwargs:
    value: '{''features_extractor_class'': <class ''utils.custom_encoder.CustomEncoder''>, ''features_extractor_kwargs'': {''features_dim'': 256}, ''net_arch'': {''pi'': [256, 256], ''qf'': [256, 256]}, ''use_sde'': False}'
replay_buffer:
    value: <stable_baselines3.common.buffers.DictReplayBuffer object at 0x7f3e3503fcb0>
replay_buffer_class:
    value: <class 'stable_baselines3.common.buffers.DictReplayBuffer'>
replay_buffer_kwargs:
    value: '{}'
sde_sample_freq:
    value: -1
seed:
    value: None
start_time:
    value: 1769409641888401412
target_entropy:
    value: -3
target_update_interval:
    value: 1
tau:
    value: 0.005
tensorboard_log:
    value: ./tb_logs/
total_timesteps:
    value: 1000000
train_freq:
    value: 'TrainFreq(frequency=1, unit=<TrainFrequencyUnit.STEP: ''step''>)'
use_sde:
    value: "False"
use_sde_at_warmup:
    value: "False"
verbose:
    value: 2
