_current_progress_remaining:
    value: 0
_custom_logger:
    value: "False"
_episode_num:
    value: 0
_last_episode_starts:
    value: '[ True]'
_last_obs:
    value: |-
        OrderedDict({'map': array([[[[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],
                 [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],
                 [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],
                 ...,
                 [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],
                 [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],
                 [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]],

                [[1. , 1. , 1. , ..., 1. , 1. , 1. ],
                 [1. , 1. , 1. , ..., 1. , 1. , 1. ],
                 [1. , 1. , 1. , ..., 1. , 1. , 1. ],
                 ...,
                 [1. , 1. , 1. , ..., 1. , 1. , 1. ],
                 [1. , 1. , 1. , ..., 1. , 1. , 1. ],
                 [1. , 1. , 1. , ..., 1. , 1. , 1. ]]]],
              shape=(1, 2, 64, 64), dtype=float32), 'pose': array([[ 0.62109375,  0.2890625 ,  0.9675046 , -0.2528533 ,  0.35442626,
                 0.00142352]], dtype=float32)})
_last_original_obs:
    value: |-
        OrderedDict({'map': array([[[[0.36684018, 0.36686864, 0.36961374, ..., 0.5       ,
                  0.5       , 0.5       ],
                 [0.36634573, 0.3683686 , 0.37162265, ..., 0.5       ,
                  0.5       , 0.5       ],
                 [0.36941627, 0.37205312, 0.37473166, ..., 0.5       ,
                  0.5       , 0.5       ],
                 ...,
                 [0.5       , 0.5       , 0.5       , ..., 0.5       ,
                  0.5       , 0.5       ],
                 [0.5       , 0.5       , 0.5       , ..., 0.5       ,
                  0.5       , 0.5       ],
                 [0.5       , 0.5       , 0.5       , ..., 0.5       ,
                  0.5       , 0.5       ]],

                [[0.73368037, 0.7337373 , 0.7392275 , ..., 1.        ,
                  1.        , 1.        ],
                 [0.73269147, 0.7367372 , 0.7432453 , ..., 1.        ,
                  1.        , 1.        ],
                 [0.73883253, 0.74410623, 0.7494633 , ..., 1.        ,
                  1.        , 1.        ],
                 ...,
                 [1.        , 1.        , 1.        , ..., 1.        ,
                  1.        , 1.        ],
                 [1.        , 1.        , 1.        , ..., 1.        ,
                  1.        , 1.        ],
                 [1.        , 1.        , 1.        , ..., 1.        ,
                  1.        , 1.        ]]]], shape=(1, 2, 64, 64), dtype=float32), 'pose': array([[ 0.59986585,  0.6521493 ,  0.97338295, -0.22918478,  0.38232377,
                -0.89830333]], dtype=float32)})
_logger:
    value: <stable_baselines3.common.logger.Logger object at 0x7fcafae31a60>
_n_updates:
    value: 10800
_num_timesteps_at_start:
    value: 0
_stats_window_size:
    value: 100
_total_timesteps:
    value: 10000
_vec_normalize_env:
    value: None
_wandb:
    value:
        cli_version: 0.23.1
        e:
            uegwq112o1mitn7o0hpsi2wbatgylaeg:
                codePath: scripts/Train_Script.py
                codePathLocal: scripts/Train_Script.py
                cpu_count: 8
                cpu_count_logical: 16
                cudaVersion: "12.8"
                disk:
                    /:
                        total: "180902232064"
                        used: "84487782400"
                email: 3297240254@qq.com
                executable: /home/fmt/miniconda3/envs/sb3/bin/python
                git:
                    commit: bce47273a5bdb072345681fb8be78cbf2a7640a6
                gpu: NVIDIA GeForce GTX 1650
                gpu_count: 1
                gpu_nvidia:
                    - architecture: Turing
                      cudaCores: 896
                      memoryTotal: "4294967296"
                      name: NVIDIA GeForce GTX 1650
                      uuid: GPU-866177ef-22d3-fdee-6758-f45e9f57a01c
                host: fmt-Lenovo-Legion-Y7000P2020
                memory:
                    total: "16623509504"
                os: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
                program: /home/fmt/catkin_ws/src/fmt_/sb3_SAC/scripts/Train_Script.py
                python: CPython 3.12.12
                root: ./
                startedAt: "2026-01-16T15:06:14.495253Z"
                writerId: uegwq112o1mitn7o0hpsi2wbatgylaeg
        m: []
        python_version: 3.12.12
        t:
            "1":
                - 1
            "2":
                - 1
            "3":
                - 13
                - 16
                - 22
                - 35
            "4": 3.12.12
            "5": 0.23.1
            "12": 0.23.1
            "13": linux-x86_64
action_noise:
    value: None
action_space:
    value: Box(-1.0, 1.0, (2,), float32)
actor:
    value: |-
        Actor(
          (features_extractor): CustomCNN(
            (cnn): Sequential(
              (0): Conv2d(2, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
              (1): ReLU()
              (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
              (3): ReLU()
              (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
              (5): ReLU()
              (6): Flatten(start_dim=1, end_dim=-1)
            )
            (pose_mlp): Sequential(
              (0): Linear(in_features=6, out_features=64, bias=True)
              (1): ReLU()
              (2): Linear(in_features=64, out_features=64, bias=True)
              (3): ReLU()
            )
            (fuse): Sequential(
              (0): Linear(in_features=4160, out_features=256, bias=True)
              (1): ReLU()
            )
          )
          (latent_pi): Sequential(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): ReLU()
            (2): Linear(in_features=256, out_features=256, bias=True)
            (3): ReLU()
          )
          (mu): Linear(in_features=256, out_features=2, bias=True)
          (log_std): Linear(in_features=256, out_features=2, bias=True)
        )
algo:
    value: SAC
batch_norm_stats:
    value: '[]'
batch_norm_stats_target:
    value: '[]'
batch_size:
    value: 256
buffer_size:
    value: 200000
critic:
    value: |-
        ContinuousCritic(
          (features_extractor): CustomCNN(
            (cnn): Sequential(
              (0): Conv2d(2, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
              (1): ReLU()
              (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
              (3): ReLU()
              (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
              (5): ReLU()
              (6): Flatten(start_dim=1, end_dim=-1)
            )
            (pose_mlp): Sequential(
              (0): Linear(in_features=6, out_features=64, bias=True)
              (1): ReLU()
              (2): Linear(in_features=64, out_features=64, bias=True)
              (3): ReLU()
            )
            (fuse): Sequential(
              (0): Linear(in_features=4160, out_features=256, bias=True)
              (1): ReLU()
            )
          )
          (qf0): Sequential(
            (0): Linear(in_features=258, out_features=256, bias=True)
            (1): ReLU()
            (2): Linear(in_features=256, out_features=256, bias=True)
            (3): ReLU()
            (4): Linear(in_features=256, out_features=1, bias=True)
          )
          (qf1): Sequential(
            (0): Linear(in_features=258, out_features=256, bias=True)
            (1): ReLU()
            (2): Linear(in_features=256, out_features=256, bias=True)
            (3): ReLU()
            (4): Linear(in_features=256, out_features=1, bias=True)
          )
        )
critic_target:
    value: |-
        ContinuousCritic(
          (features_extractor): CustomCNN(
            (cnn): Sequential(
              (0): Conv2d(2, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
              (1): ReLU()
              (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
              (3): ReLU()
              (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
              (5): ReLU()
              (6): Flatten(start_dim=1, end_dim=-1)
            )
            (pose_mlp): Sequential(
              (0): Linear(in_features=6, out_features=64, bias=True)
              (1): ReLU()
              (2): Linear(in_features=64, out_features=64, bias=True)
              (3): ReLU()
            )
            (fuse): Sequential(
              (0): Linear(in_features=4160, out_features=256, bias=True)
              (1): ReLU()
            )
          )
          (qf0): Sequential(
            (0): Linear(in_features=258, out_features=256, bias=True)
            (1): ReLU()
            (2): Linear(in_features=256, out_features=256, bias=True)
            (3): ReLU()
            (4): Linear(in_features=256, out_features=1, bias=True)
          )
          (qf1): Sequential(
            (0): Linear(in_features=258, out_features=256, bias=True)
            (1): ReLU()
            (2): Linear(in_features=256, out_features=256, bias=True)
            (3): ReLU()
            (4): Linear(in_features=256, out_features=1, bias=True)
          )
        )
device:
    value: cuda
ent_coef:
    value: auto
ent_coef_optimizer:
    value: |-
        Adam (
        Parameter Group 0
            amsgrad: False
            betas: (0.9, 0.999)
            capturable: False
            decoupled_weight_decay: False
            differentiable: False
            eps: 1e-08
            foreach: None
            fused: None
            lr: 0.0003
            maximize: False
            weight_decay: 0
        )
env:
    value: <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7fcb29f31d30>
ep_info_buffer:
    value: deque([], maxlen=100)
ep_success_buffer:
    value: deque([], maxlen=100)
features_dim:
    value: 256
gamma:
    value: 0.99
gradient_steps:
    value: 1
learning_rate:
    value: 0.0003
learning_starts:
    value: 100
log_ent_coef:
    value: tensor([-1.5695], device='cuda:0', requires_grad=True)
lr_schedule:
    value: FloatSchedule(ConstantSchedule(val=0.0003))
n_envs:
    value: 1
n_steps:
    value: 1
net_arch:
    value:
        - 256
        - 256
num_timesteps:
    value: 0
observation_space:
    value: 'Dict(''map'': Box(0.0, 1.0, (2, 64, 64), float32), ''pose'': Box(-1.0, 1.0, (6,), float32))'
optimize_memory_usage:
    value: "False"
policy:
    value: |-
        MultiInputPolicy(
          (actor): Actor(
            (features_extractor): CustomCNN(
              (cnn): Sequential(
                (0): Conv2d(2, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
                (1): ReLU()
                (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
                (3): ReLU()
                (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
                (5): ReLU()
                (6): Flatten(start_dim=1, end_dim=-1)
              )
              (pose_mlp): Sequential(
                (0): Linear(in_features=6, out_features=64, bias=True)
                (1): ReLU()
                (2): Linear(in_features=64, out_features=64, bias=True)
                (3): ReLU()
              )
              (fuse): Sequential(
                (0): Linear(in_features=4160, out_features=256, bias=True)
                (1): ReLU()
              )
            )
            (latent_pi): Sequential(
              (0): Linear(in_features=256, out_features=256, bias=True)
              (1): ReLU()
              (2): Linear(in_features=256, out_features=256, bias=True)
              (3): ReLU()
            )
            (mu): Linear(in_features=256, out_features=2, bias=True)
            (log_std): Linear(in_features=256, out_features=2, bias=True)
          )
          (critic): ContinuousCritic(
            (features_extractor): CustomCNN(
              (cnn): Sequential(
                (0): Conv2d(2, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
                (1): ReLU()
                (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
                (3): ReLU()
                (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
                (5): ReLU()
                (6): Flatten(start_dim=1, end_dim=-1)
              )
              (pose_mlp): Sequential(
                (0): Linear(in_features=6, out_features=64, bias=True)
                (1): ReLU()
                (2): Linear(in_features=64, out_features=64, bias=True)
                (3): ReLU()
              )
              (fuse): Sequential(
                (0): Linear(in_features=4160, out_features=256, bias=True)
                (1): ReLU()
              )
            )
            (qf0): Sequential(
              (0): Linear(in_features=258, out_features=256, bias=True)
              (1): ReLU()
              (2): Linear(in_features=256, out_features=256, bias=True)
              (3): ReLU()
              (4): Linear(in_features=256, out_features=1, bias=True)
            )
            (qf1): Sequential(
              (0): Linear(in_features=258, out_features=256, bias=True)
              (1): ReLU()
              (2): Linear(in_features=256, out_features=256, bias=True)
              (3): ReLU()
              (4): Linear(in_features=256, out_features=1, bias=True)
            )
          )
          (critic_target): ContinuousCritic(
            (features_extractor): CustomCNN(
              (cnn): Sequential(
                (0): Conv2d(2, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
                (1): ReLU()
                (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
                (3): ReLU()
                (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
                (5): ReLU()
                (6): Flatten(start_dim=1, end_dim=-1)
              )
              (pose_mlp): Sequential(
                (0): Linear(in_features=6, out_features=64, bias=True)
                (1): ReLU()
                (2): Linear(in_features=64, out_features=64, bias=True)
                (3): ReLU()
              )
              (fuse): Sequential(
                (0): Linear(in_features=4160, out_features=256, bias=True)
                (1): ReLU()
              )
            )
            (qf0): Sequential(
              (0): Linear(in_features=258, out_features=256, bias=True)
              (1): ReLU()
              (2): Linear(in_features=256, out_features=256, bias=True)
              (3): ReLU()
              (4): Linear(in_features=256, out_features=1, bias=True)
            )
            (qf1): Sequential(
              (0): Linear(in_features=258, out_features=256, bias=True)
              (1): ReLU()
              (2): Linear(in_features=256, out_features=256, bias=True)
              (3): ReLU()
              (4): Linear(in_features=256, out_features=1, bias=True)
            )
          )
        )
policy_class:
    value: <class 'stable_baselines3.sac.policies.MultiInputPolicy'>
policy_kwargs:
    value: '{''features_extractor_class'': <class ''utils.custom_cnn.CustomCNN''>, ''features_extractor_kwargs'': {''features_dim'': 256}, ''net_arch'': {''pi'': [256, 256], ''qf'': [256, 256]}, ''use_sde'': False}'
replay_buffer:
    value: <stable_baselines3.common.buffers.DictReplayBuffer object at 0x7fcafd36c200>
replay_buffer_class:
    value: <class 'stable_baselines3.common.buffers.DictReplayBuffer'>
replay_buffer_kwargs:
    value: '{}'
sde_sample_freq:
    value: -1
seed:
    value: None
start_time:
    value: 1768575978978222410
target_entropy:
    value: -2
target_update_interval:
    value: 1
tau:
    value: 0.005
tensorboard_log:
    value: ./tb_logs/
total_timesteps:
    value: 10000
train_freq:
    value: 'TrainFreq(frequency=1, unit=<TrainFrequencyUnit.STEP: ''step''>)'
use_sde:
    value: "False"
use_sde_at_warmup:
    value: "False"
verbose:
    value: 2
