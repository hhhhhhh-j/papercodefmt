2026-01-26 15:32:12,913 INFO    MainThread:54148 [wandb_setup.py:_flush():80] Current SDK version is 0.23.1
2026-01-26 15:32:12,914 INFO    MainThread:54148 [wandb_setup.py:_flush():80] Configure stats pid to 54148
2026-01-26 15:32:12,914 INFO    MainThread:54148 [wandb_setup.py:_flush():80] Loading settings from /home/fmt/.config/wandb/settings
2026-01-26 15:32:12,914 INFO    MainThread:54148 [wandb_setup.py:_flush():80] Loading settings from /home/fmt/catkin_ws/src/fmt_/sb3_SAC/wandb/settings
2026-01-26 15:32:12,914 INFO    MainThread:54148 [wandb_setup.py:_flush():80] Loading settings from environment variables
2026-01-26 15:32:12,914 INFO    MainThread:54148 [wandb_init.py:setup_run_log_directory():714] Logging user logs to wandb/run-20260126_153212-9rm07f50/logs/debug.log
2026-01-26 15:32:12,914 INFO    MainThread:54148 [wandb_init.py:setup_run_log_directory():715] Logging internal logs to wandb/run-20260126_153212-9rm07f50/logs/debug-internal.log
2026-01-26 15:32:12,916 INFO    MainThread:54148 [wandb_init.py:init():841] calling init triggers
2026-01-26 15:32:12,916 INFO    MainThread:54148 [wandb_init.py:init():846] wandb.init called with sweep_config: {}
config: {'learning_rate': 0.0003, 'buffer_size': 10000, 'batch_size': 32, 'gamma': 0.99, 'tau': 0.005, 'net_arch': [256, 256], 'features_dim': 256, 'total_timesteps': 1000000, '_wandb': {}}
2026-01-26 15:32:12,916 INFO    MainThread:54148 [wandb_init.py:init():889] starting backend
2026-01-26 15:32:13,135 INFO    MainThread:54148 [wandb_init.py:init():892] sending inform_init request
2026-01-26 15:32:13,139 INFO    MainThread:54148 [wandb_init.py:init():900] backend started and connected
2026-01-26 15:32:13,151 INFO    MainThread:54148 [wandb_init.py:init():970] updated telemetry
2026-01-26 15:32:13,153 INFO    MainThread:54148 [wandb_init.py:init():994] communicating run to backend with 90.0 second timeout
2026-01-26 15:32:16,578 INFO    MainThread:54148 [wandb_init.py:init():1041] starting run threads in backend
2026-01-26 15:32:16,659 INFO    MainThread:54148 [wandb_run.py:_console_start():2521] atexit reg
2026-01-26 15:32:16,659 INFO    MainThread:54148 [wandb_run.py:_redirect():2369] redirect: wrap_raw
2026-01-26 15:32:16,659 INFO    MainThread:54148 [wandb_run.py:_redirect():2438] Wrapping output streams.
2026-01-26 15:32:16,659 INFO    MainThread:54148 [wandb_run.py:_redirect():2461] Redirects installed.
2026-01-26 15:32:16,661 INFO    MainThread:54148 [wandb_init.py:init():1081] run started, returning control to user process
2026-01-26 15:32:17,695 INFO    MainThread:54148 [wandb_run.py:_tensorboard_callback():1607] tensorboard callback: ./tb_logs/SAC_38, True
2026-01-26 15:32:17,732 INFO    MainThread:54148 [wandb_run.py:_config_callback():1396] config_cb None None {'algo': 'SAC', 'policy_class': "<class 'stable_baselines3.sac.policies.MultiInputPolicy'>", 'device': 'cuda', 'verbose': 2, 'policy_kwargs': "{'features_extractor_class': <class 'utils.custom_encoder.CustomEncoder'>, 'features_extractor_kwargs': {'features_dim': 256}, 'net_arch': {'pi': [256, 256], 'qf': [256, 256]}, 'use_sde': False}", 'num_timesteps': 0, '_total_timesteps': 1000000, '_num_timesteps_at_start': 0, 'seed': 'None', 'action_noise': 'None', 'start_time': 1769412737645676951, 'tensorboard_log': './tb_logs/', '_last_obs': "OrderedDict({'global_map': array([[[[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[1., 1., 1., ..., 1., 1., 1.],\n         [1., 1., 1., ..., 1., 1., 1.],\n         [1., 1., 1., ..., 1., 1., 1.],\n         ...,\n         [1., 1., 1., ..., 1., 1., 1.],\n         [1., 1., 1., ..., 1., 1., 1.],\n         [1., 1., 1., ..., 1., 1., 1.]]]],\n      shape=(1, 4, 256, 256), dtype=float32), 'local_map': array([[[[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[1., 1., 1., ..., 1., 1., 1.],\n         [1., 1., 1., ..., 1., 1., 1.],\n         [1., 1., 1., ..., 1., 1., 1.],\n         ...,\n         [1., 1., 1., ..., 1., 1., 1.],\n         [1., 1., 1., ..., 1., 1., 1.],\n         [1., 1., 1., ..., 1., 1., 1.]]]],\n      shape=(1, 4, 64, 64), dtype=float32), 'pose': array([[ 0.12890625,  0.5234375 , -0.9896448 , -0.14353806,  0.20782204,\n        -0.52541065]], dtype=float32)})", '_last_episode_starts': '[ True]', '_last_original_obs': 'None', '_episode_num': 0, 'use_sde': 'False', 'sde_sample_freq': -1, '_current_progress_remaining': 1.0, '_stats_window_size': 100, 'ep_info_buffer': 'deque([], maxlen=100)', 'ep_success_buffer': 'deque([], maxlen=100)', '_n_updates': 0, '_custom_logger': 'False', 'env': '<stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f3a30af1dc0>', '_vec_normalize_env': 'None', 'observation_space': "Dict('global_map': Box(0.0, 1.0, (4, 256, 256), float32), 'local_map': Box(0.0, 1.0, (4, 64, 64), float32), 'pose': Box(-1.0, 1.0, (6,), float32))", 'action_space': 'Box(-1.0, 1.0, (3,), float32)', 'n_envs': 1, 'learning_starts': 100, 'gradient_steps': 1, 'optimize_memory_usage': 'False', 'replay_buffer': '<stable_baselines3.common.buffers.DictReplayBuffer object at 0x7f3a01b86a50>', 'replay_buffer_class': "<class 'stable_baselines3.common.buffers.DictReplayBuffer'>", 'replay_buffer_kwargs': '{}', 'n_steps': 1, 'train_freq': "TrainFreq(frequency=1, unit=<TrainFrequencyUnit.STEP: 'step'>)", 'use_sde_at_warmup': 'False', 'target_entropy': -3.0, 'log_ent_coef': "tensor([0.], device='cuda:0', requires_grad=True)", 'ent_coef': 'auto', 'target_update_interval': 1, 'ent_coef_optimizer': 'Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)', 'lr_schedule': 'FloatSchedule(ConstantSchedule(val=0.0003))', 'policy': 'MultiInputPolicy(\n  (actor): Actor(\n    (features_extractor): CustomEncoder(\n      (cnn_global): Sequential(\n        (0): Conv2d(4, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n        (1): GroupNorm(8, 16, eps=1e-05, affine=True)\n        (2): ReLU()\n        (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (4): GroupNorm(8, 32, eps=1e-05, affine=True)\n        (5): ReLU()\n        (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (7): GroupNorm(8, 64, eps=1e-05, affine=True)\n        (8): ReLU()\n        (9): AdaptiveAvgPool2d(output_size=(1, 1))\n        (10): Flatten(start_dim=1, end_dim=-1)\n      )\n      (cnn_local): Sequential(\n        (0): Conv2d(4, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n        (1): GroupNorm(8, 16, eps=1e-05, affine=True)\n        (2): ReLU()\n        (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (4): GroupNorm(8, 32, eps=1e-05, affine=True)\n        (5): ReLU()\n        (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (7): GroupNorm(8, 64, eps=1e-05, affine=True)\n        (8): ReLU()\n        (9): AdaptiveAvgPool2d(output_size=(1, 1))\n        (10): Flatten(start_dim=1, end_dim=-1)\n      )\n      (pose_mlp): Sequential(\n        (0): Linear(in_features=6, out_features=64, bias=True)\n        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n        (2): ReLU()\n        (3): Linear(in_features=64, out_features=64, bias=True)\n        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n        (5): ReLU()\n      )\n      (fuse): Sequential(\n        (0): Linear(in_features=192, out_features=256, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=256, out_features=256, bias=True)\n        (3): ReLU()\n      )\n    )\n    (latent_pi): Sequential(\n      (0): Linear(in_features=256, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n    )\n    (mu): Linear(in_features=256, out_features=3, bias=True)\n    (log_std): Linear(in_features=256, out_features=3, bias=True)\n  )\n  (critic): ContinuousCritic(\n    (features_extractor): CustomEncoder(\n      (cnn_global): Sequential(\n        (0): Conv2d(4, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n        (1): GroupNorm(8, 16, eps=1e-05, affine=True)\n        (2): ReLU()\n        (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (4): GroupNorm(8, 32, eps=1e-05, affine=True)\n        (5): ReLU()\n        (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (7): GroupNorm(8, 64, eps=1e-05, affine=True)\n        (8): ReLU()\n        (9): AdaptiveAvgPool2d(output_size=(1, 1))\n        (10): Flatten(start_dim=1, end_dim=-1)\n      )\n      (cnn_local): Sequential(\n        (0): Conv2d(4, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n        (1): GroupNorm(8, 16, eps=1e-05, affine=True)\n        (2): ReLU()\n        (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (4): GroupNorm(8, 32, eps=1e-05, affine=True)\n        (5): ReLU()\n        (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (7): GroupNorm(8, 64, eps=1e-05, affine=True)\n        (8): ReLU()\n        (9): AdaptiveAvgPool2d(output_size=(1, 1))\n        (10): Flatten(start_dim=1, end_dim=-1)\n      )\n      (pose_mlp): Sequential(\n        (0): Linear(in_features=6, out_features=64, bias=True)\n        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n        (2): ReLU()\n        (3): Linear(in_features=64, out_features=64, bias=True)\n        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n        (5): ReLU()\n      )\n      (fuse): Sequential(\n        (0): Linear(in_features=192, out_features=256, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=256, out_features=256, bias=True)\n        (3): ReLU()\n      )\n    )\n    (qf0): Sequential(\n      (0): Linear(in_features=259, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=256, out_features=1, bias=True)\n    )\n    (qf1): Sequential(\n      (0): Linear(in_features=259, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=256, out_features=1, bias=True)\n    )\n  )\n  (critic_target): ContinuousCritic(\n    (features_extractor): CustomEncoder(\n      (cnn_global): Sequential(\n        (0): Conv2d(4, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n        (1): GroupNorm(8, 16, eps=1e-05, affine=True)\n        (2): ReLU()\n        (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (4): GroupNorm(8, 32, eps=1e-05, affine=True)\n        (5): ReLU()\n        (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (7): GroupNorm(8, 64, eps=1e-05, affine=True)\n        (8): ReLU()\n        (9): AdaptiveAvgPool2d(output_size=(1, 1))\n        (10): Flatten(start_dim=1, end_dim=-1)\n      )\n      (cnn_local): Sequential(\n        (0): Conv2d(4, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n        (1): GroupNorm(8, 16, eps=1e-05, affine=True)\n        (2): ReLU()\n        (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (4): GroupNorm(8, 32, eps=1e-05, affine=True)\n        (5): ReLU()\n        (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (7): GroupNorm(8, 64, eps=1e-05, affine=True)\n        (8): ReLU()\n        (9): AdaptiveAvgPool2d(output_size=(1, 1))\n        (10): Flatten(start_dim=1, end_dim=-1)\n      )\n      (pose_mlp): Sequential(\n        (0): Linear(in_features=6, out_features=64, bias=True)\n        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n        (2): ReLU()\n        (3): Linear(in_features=64, out_features=64, bias=True)\n        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n        (5): ReLU()\n      )\n      (fuse): Sequential(\n        (0): Linear(in_features=192, out_features=256, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=256, out_features=256, bias=True)\n        (3): ReLU()\n      )\n    )\n    (qf0): Sequential(\n      (0): Linear(in_features=259, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=256, out_features=1, bias=True)\n    )\n    (qf1): Sequential(\n      (0): Linear(in_features=259, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=256, out_features=1, bias=True)\n    )\n  )\n)', 'actor': 'Actor(\n  (features_extractor): CustomEncoder(\n    (cnn_global): Sequential(\n      (0): Conv2d(4, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n      (1): GroupNorm(8, 16, eps=1e-05, affine=True)\n      (2): ReLU()\n      (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (4): GroupNorm(8, 32, eps=1e-05, affine=True)\n      (5): ReLU()\n      (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (7): GroupNorm(8, 64, eps=1e-05, affine=True)\n      (8): ReLU()\n      (9): AdaptiveAvgPool2d(output_size=(1, 1))\n      (10): Flatten(start_dim=1, end_dim=-1)\n    )\n    (cnn_local): Sequential(\n      (0): Conv2d(4, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n      (1): GroupNorm(8, 16, eps=1e-05, affine=True)\n      (2): ReLU()\n      (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (4): GroupNorm(8, 32, eps=1e-05, affine=True)\n      (5): ReLU()\n      (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (7): GroupNorm(8, 64, eps=1e-05, affine=True)\n      (8): ReLU()\n      (9): AdaptiveAvgPool2d(output_size=(1, 1))\n      (10): Flatten(start_dim=1, end_dim=-1)\n    )\n    (pose_mlp): Sequential(\n      (0): Linear(in_features=6, out_features=64, bias=True)\n      (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n      (2): ReLU()\n      (3): Linear(in_features=64, out_features=64, bias=True)\n      (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n      (5): ReLU()\n    )\n    (fuse): Sequential(\n      (0): Linear(in_features=192, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n    )\n  )\n  (latent_pi): Sequential(\n    (0): Linear(in_features=256, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n    (3): ReLU()\n  )\n  (mu): Linear(in_features=256, out_features=3, bias=True)\n  (log_std): Linear(in_features=256, out_features=3, bias=True)\n)', 'critic': 'ContinuousCritic(\n  (features_extractor): CustomEncoder(\n    (cnn_global): Sequential(\n      (0): Conv2d(4, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n      (1): GroupNorm(8, 16, eps=1e-05, affine=True)\n      (2): ReLU()\n      (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (4): GroupNorm(8, 32, eps=1e-05, affine=True)\n      (5): ReLU()\n      (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (7): GroupNorm(8, 64, eps=1e-05, affine=True)\n      (8): ReLU()\n      (9): AdaptiveAvgPool2d(output_size=(1, 1))\n      (10): Flatten(start_dim=1, end_dim=-1)\n    )\n    (cnn_local): Sequential(\n      (0): Conv2d(4, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n      (1): GroupNorm(8, 16, eps=1e-05, affine=True)\n      (2): ReLU()\n      (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (4): GroupNorm(8, 32, eps=1e-05, affine=True)\n      (5): ReLU()\n      (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (7): GroupNorm(8, 64, eps=1e-05, affine=True)\n      (8): ReLU()\n      (9): AdaptiveAvgPool2d(output_size=(1, 1))\n      (10): Flatten(start_dim=1, end_dim=-1)\n    )\n    (pose_mlp): Sequential(\n      (0): Linear(in_features=6, out_features=64, bias=True)\n      (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n      (2): ReLU()\n      (3): Linear(in_features=64, out_features=64, bias=True)\n      (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n      (5): ReLU()\n    )\n    (fuse): Sequential(\n      (0): Linear(in_features=192, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n    )\n  )\n  (qf0): Sequential(\n    (0): Linear(in_features=259, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n  )\n  (qf1): Sequential(\n    (0): Linear(in_features=259, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n  )\n)', 'critic_target': 'ContinuousCritic(\n  (features_extractor): CustomEncoder(\n    (cnn_global): Sequential(\n      (0): Conv2d(4, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n      (1): GroupNorm(8, 16, eps=1e-05, affine=True)\n      (2): ReLU()\n      (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (4): GroupNorm(8, 32, eps=1e-05, affine=True)\n      (5): ReLU()\n      (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (7): GroupNorm(8, 64, eps=1e-05, affine=True)\n      (8): ReLU()\n      (9): AdaptiveAvgPool2d(output_size=(1, 1))\n      (10): Flatten(start_dim=1, end_dim=-1)\n    )\n    (cnn_local): Sequential(\n      (0): Conv2d(4, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n      (1): GroupNorm(8, 16, eps=1e-05, affine=True)\n      (2): ReLU()\n      (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (4): GroupNorm(8, 32, eps=1e-05, affine=True)\n      (5): ReLU()\n      (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (7): GroupNorm(8, 64, eps=1e-05, affine=True)\n      (8): ReLU()\n      (9): AdaptiveAvgPool2d(output_size=(1, 1))\n      (10): Flatten(start_dim=1, end_dim=-1)\n    )\n    (pose_mlp): Sequential(\n      (0): Linear(in_features=6, out_features=64, bias=True)\n      (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n      (2): ReLU()\n      (3): Linear(in_features=64, out_features=64, bias=True)\n      (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n      (5): ReLU()\n    )\n    (fuse): Sequential(\n      (0): Linear(in_features=192, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n    )\n  )\n  (qf0): Sequential(\n    (0): Linear(in_features=259, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n  )\n  (qf1): Sequential(\n    (0): Linear(in_features=259, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n  )\n)', 'batch_norm_stats': '[]', 'batch_norm_stats_target': '[]', '_logger': '<stable_baselines3.common.logger.Logger object at 0x7f34aac97bc0>'}
2026-01-26 15:33:33,714 INFO    wandb-AsyncioManager-main:54148 [service_client.py:_forward_responses():80] Reached EOF.
2026-01-26 15:33:33,714 INFO    wandb-AsyncioManager-main:54148 [mailbox.py:close():137] Closing mailbox, abandoning 1 handles.
