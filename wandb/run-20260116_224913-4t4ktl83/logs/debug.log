2026-01-16 22:49:13,919 INFO    MainThread:51694 [wandb_setup.py:_flush():80] Current SDK version is 0.23.1
2026-01-16 22:49:13,919 INFO    MainThread:51694 [wandb_setup.py:_flush():80] Configure stats pid to 51694
2026-01-16 22:49:13,919 INFO    MainThread:51694 [wandb_setup.py:_flush():80] Loading settings from /home/fmt/.config/wandb/settings
2026-01-16 22:49:13,919 INFO    MainThread:51694 [wandb_setup.py:_flush():80] Loading settings from /home/fmt/catkin_ws/src/fmt_/sb3_SAC/wandb/settings
2026-01-16 22:49:13,919 INFO    MainThread:51694 [wandb_setup.py:_flush():80] Loading settings from environment variables
2026-01-16 22:49:13,920 INFO    MainThread:51694 [wandb_init.py:setup_run_log_directory():714] Logging user logs to wandb/run-20260116_224913-4t4ktl83/logs/debug.log
2026-01-16 22:49:13,920 INFO    MainThread:51694 [wandb_init.py:setup_run_log_directory():715] Logging internal logs to wandb/run-20260116_224913-4t4ktl83/logs/debug-internal.log
2026-01-16 22:49:13,921 INFO    MainThread:51694 [wandb_init.py:init():841] calling init triggers
2026-01-16 22:49:13,921 INFO    MainThread:51694 [wandb_init.py:init():846] wandb.init called with sweep_config: {}
config: {'learning_rate': 0.0003, 'buffer_size': 200000, 'batch_size': 256, 'gamma': 0.99, 'tau': 0.005, 'net_arch': [256, 256], 'features_dim': 256, 'total_timesteps': 10000, '_wandb': {}}
2026-01-16 22:49:13,921 INFO    MainThread:51694 [wandb_init.py:init():889] starting backend
2026-01-16 22:49:14,137 INFO    MainThread:51694 [wandb_init.py:init():892] sending inform_init request
2026-01-16 22:49:14,147 INFO    MainThread:51694 [wandb_init.py:init():900] backend started and connected
2026-01-16 22:49:14,159 INFO    MainThread:51694 [wandb_init.py:init():970] updated telemetry
2026-01-16 22:49:14,161 INFO    MainThread:51694 [wandb_init.py:init():994] communicating run to backend with 90.0 second timeout
2026-01-16 22:49:16,149 INFO    MainThread:51694 [wandb_init.py:init():1041] starting run threads in backend
2026-01-16 22:49:16,213 INFO    MainThread:51694 [wandb_run.py:_console_start():2521] atexit reg
2026-01-16 22:49:16,213 INFO    MainThread:51694 [wandb_run.py:_redirect():2369] redirect: wrap_raw
2026-01-16 22:49:16,213 INFO    MainThread:51694 [wandb_run.py:_redirect():2438] Wrapping output streams.
2026-01-16 22:49:16,213 INFO    MainThread:51694 [wandb_run.py:_redirect():2461] Redirects installed.
2026-01-16 22:49:16,216 INFO    MainThread:51694 [wandb_init.py:init():1081] run started, returning control to user process
2026-01-16 22:49:17,101 INFO    MainThread:51694 [wandb_run.py:_tensorboard_callback():1607] tensorboard callback: ./tb_logs/SAC_4, True
2026-01-16 22:49:17,160 INFO    MainThread:51694 [wandb_run.py:_config_callback():1396] config_cb None None {'algo': 'SAC', 'policy_class': "<class 'stable_baselines3.sac.policies.MultiInputPolicy'>", 'device': 'cuda', 'verbose': 2, 'policy_kwargs': "{'features_extractor_class': <class 'utils.custom_cnn.CustomCNN'>, 'features_extractor_kwargs': {'features_dim': 256}, 'net_arch': {'pi': [256, 256], 'qf': [256, 256]}, 'use_sde': False}", 'num_timesteps': 0, '_total_timesteps': 10000, '_num_timesteps_at_start': 0, 'seed': 'None', 'action_noise': 'None', 'start_time': 1768574957054350341, 'tensorboard_log': './tb_logs/', '_last_obs': "OrderedDict({'map': array([[[[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n         [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n         [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n         ...,\n         [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n         [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n         [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]],\n\n        [[1. , 1. , 1. , ..., 1. , 1. , 1. ],\n         [1. , 1. , 1. , ..., 1. , 1. , 1. ],\n         [1. , 1. , 1. , ..., 1. , 1. , 1. ],\n         ...,\n         [1. , 1. , 1. , ..., 1. , 1. , 1. ],\n         [1. , 1. , 1. , ..., 1. , 1. , 1. ],\n         [1. , 1. , 1. , ..., 1. , 1. , 1. ]]]],\n      shape=(1, 2, 64, 64), dtype=float32), 'pose': array([[ 0.47265625,  0.703125  ,  0.30082434, -0.95367956,  0.20208946,\n         0.1541218 ]], dtype=float32)})", '_last_episode_starts': '[ True]', '_last_original_obs': "OrderedDict({'map': array([[[[5.0000000e-01, 5.0000000e-01, 5.0000000e-01, ...,\n          2.9286356e-03, 1.4349577e-03, 1.3920034e-03],\n         [5.0000000e-01, 5.0000000e-01, 5.0000000e-01, ...,\n          2.8332262e-03, 1.9402275e-03, 1.4092523e-03],\n         [5.0000000e-01, 5.0000000e-01, 5.0000000e-01, ...,\n          1.3777519e-03, 2.1569625e-02, 9.5383305e-04],\n         ...,\n         [5.0000000e-01, 5.0000000e-01, 5.0000000e-01, ...,\n          5.0000000e-01, 5.0000000e-01, 5.0000000e-01],\n         [5.0000000e-01, 5.0000000e-01, 5.0000000e-01, ...,\n          5.0000000e-01, 5.0000000e-01, 5.0000000e-01],\n         [5.0000000e-01, 5.0000000e-01, 5.0000000e-01, ...,\n          5.0000000e-01, 5.0000000e-01, 5.0000000e-01]],\n\n        [[1.0000000e+00, 1.0000000e+00, 1.0000000e+00, ...,\n          5.8572711e-03, 2.8699154e-03, 2.7840068e-03],\n         [1.0000000e+00, 1.0000000e+00, 1.0000000e+00, ...,\n          5.6664525e-03, 3.8804549e-03, 2.8185046e-03],\n         [1.0000000e+00, 1.0000000e+00, 1.0000000e+00, ...,\n          2.7555039e-03, 3.7392487e-03, 1.9076661e-03],\n         ...,\n         [1.0000000e+00, 1.0000000e+00, 1.0000000e+00, ...,\n          1.0000000e+00, 1.0000000e+00, 1.0000000e+00],\n         [1.0000000e+00, 1.0000000e+00, 1.0000000e+00, ...,\n          1.0000000e+00, 1.0000000e+00, 1.0000000e+00],\n         [1.0000000e+00, 1.0000000e+00, 1.0000000e+00, ...,\n          1.0000000e+00, 1.0000000e+00, 1.0000000e+00]]]],\n      shape=(1, 2, 64, 64), dtype=float32), 'pose': array([[ 0.50780064,  0.23473068,  0.01043497, -0.9999456 ,  0.16269657,\n         0.11988583]], dtype=float32)})", '_episode_num': 0, 'use_sde': 'False', 'sde_sample_freq': -1, '_current_progress_remaining': 0.0, '_stats_window_size': 100, 'ep_info_buffer': 'deque([], maxlen=100)', 'ep_success_buffer': 'deque([], maxlen=100)', '_n_updates': 900, '_custom_logger': 'False', 'env': '<stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f02e60e9e50>', '_vec_normalize_env': 'None', 'observation_space': "Dict('map': Box(0.0, 1.0, (2, 64, 64), float32), 'pose': Box(-1.0, 1.0, (6,), float32))", 'action_space': 'Box(-1.0, 1.0, (2,), float32)', 'n_envs': 1, 'learning_starts': 100, 'gradient_steps': 1, 'optimize_memory_usage': 'False', 'replay_buffer': '<stable_baselines3.common.buffers.DictReplayBuffer object at 0x7f02b70e1a60>', 'replay_buffer_class': "<class 'stable_baselines3.common.buffers.DictReplayBuffer'>", 'replay_buffer_kwargs': '{}', 'n_steps': 1, 'train_freq': "TrainFreq(frequency=1, unit=<TrainFrequencyUnit.STEP: 'step'>)", 'use_sde_at_warmup': 'False', 'target_entropy': -2.0, 'log_ent_coef': "tensor([-0.2463], device='cuda:0', requires_grad=True)", 'ent_coef': 'auto', 'target_update_interval': 1, 'ent_coef_optimizer': 'Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)', 'lr_schedule': 'FloatSchedule(ConstantSchedule(val=0.0003))', 'batch_norm_stats': '[]', 'batch_norm_stats_target': '[]', 'policy': 'MultiInputPolicy(\n  (actor): Actor(\n    (features_extractor): CustomCNN(\n      (cnn): Sequential(\n        (0): Conv2d(2, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n        (1): ReLU()\n        (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        (3): ReLU()\n        (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        (5): ReLU()\n        (6): Flatten(start_dim=1, end_dim=-1)\n      )\n      (pose_mlp): Sequential(\n        (0): Linear(in_features=6, out_features=64, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=64, out_features=64, bias=True)\n        (3): ReLU()\n      )\n      (fuse): Sequential(\n        (0): Linear(in_features=4160, out_features=256, bias=True)\n        (1): ReLU()\n      )\n    )\n    (latent_pi): Sequential(\n      (0): Linear(in_features=256, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n    )\n    (mu): Linear(in_features=256, out_features=2, bias=True)\n    (log_std): Linear(in_features=256, out_features=2, bias=True)\n  )\n  (critic): ContinuousCritic(\n    (features_extractor): CustomCNN(\n      (cnn): Sequential(\n        (0): Conv2d(2, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n        (1): ReLU()\n        (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        (3): ReLU()\n        (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        (5): ReLU()\n        (6): Flatten(start_dim=1, end_dim=-1)\n      )\n      (pose_mlp): Sequential(\n        (0): Linear(in_features=6, out_features=64, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=64, out_features=64, bias=True)\n        (3): ReLU()\n      )\n      (fuse): Sequential(\n        (0): Linear(in_features=4160, out_features=256, bias=True)\n        (1): ReLU()\n      )\n    )\n    (qf0): Sequential(\n      (0): Linear(in_features=258, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=256, out_features=1, bias=True)\n    )\n    (qf1): Sequential(\n      (0): Linear(in_features=258, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=256, out_features=1, bias=True)\n    )\n  )\n  (critic_target): ContinuousCritic(\n    (features_extractor): CustomCNN(\n      (cnn): Sequential(\n        (0): Conv2d(2, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n        (1): ReLU()\n        (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        (3): ReLU()\n        (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        (5): ReLU()\n        (6): Flatten(start_dim=1, end_dim=-1)\n      )\n      (pose_mlp): Sequential(\n        (0): Linear(in_features=6, out_features=64, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=64, out_features=64, bias=True)\n        (3): ReLU()\n      )\n      (fuse): Sequential(\n        (0): Linear(in_features=4160, out_features=256, bias=True)\n        (1): ReLU()\n      )\n    )\n    (qf0): Sequential(\n      (0): Linear(in_features=258, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=256, out_features=1, bias=True)\n    )\n    (qf1): Sequential(\n      (0): Linear(in_features=258, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=256, out_features=1, bias=True)\n    )\n  )\n)', 'actor': 'Actor(\n  (features_extractor): CustomCNN(\n    (cnn): Sequential(\n      (0): Conv2d(2, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n      (1): ReLU()\n      (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (3): ReLU()\n      (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (5): ReLU()\n      (6): Flatten(start_dim=1, end_dim=-1)\n    )\n    (pose_mlp): Sequential(\n      (0): Linear(in_features=6, out_features=64, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): ReLU()\n    )\n    (fuse): Sequential(\n      (0): Linear(in_features=4160, out_features=256, bias=True)\n      (1): ReLU()\n    )\n  )\n  (latent_pi): Sequential(\n    (0): Linear(in_features=256, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n    (3): ReLU()\n  )\n  (mu): Linear(in_features=256, out_features=2, bias=True)\n  (log_std): Linear(in_features=256, out_features=2, bias=True)\n)', 'critic': 'ContinuousCritic(\n  (features_extractor): CustomCNN(\n    (cnn): Sequential(\n      (0): Conv2d(2, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n      (1): ReLU()\n      (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (3): ReLU()\n      (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (5): ReLU()\n      (6): Flatten(start_dim=1, end_dim=-1)\n    )\n    (pose_mlp): Sequential(\n      (0): Linear(in_features=6, out_features=64, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): ReLU()\n    )\n    (fuse): Sequential(\n      (0): Linear(in_features=4160, out_features=256, bias=True)\n      (1): ReLU()\n    )\n  )\n  (qf0): Sequential(\n    (0): Linear(in_features=258, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n  )\n  (qf1): Sequential(\n    (0): Linear(in_features=258, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n  )\n)', 'critic_target': 'ContinuousCritic(\n  (features_extractor): CustomCNN(\n    (cnn): Sequential(\n      (0): Conv2d(2, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n      (1): ReLU()\n      (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (3): ReLU()\n      (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (5): ReLU()\n      (6): Flatten(start_dim=1, end_dim=-1)\n    )\n    (pose_mlp): Sequential(\n      (0): Linear(in_features=6, out_features=64, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): ReLU()\n    )\n    (fuse): Sequential(\n      (0): Linear(in_features=4160, out_features=256, bias=True)\n      (1): ReLU()\n    )\n  )\n  (qf0): Sequential(\n    (0): Linear(in_features=258, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n  )\n  (qf1): Sequential(\n    (0): Linear(in_features=258, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n  )\n)', '_logger': '<stable_baselines3.common.logger.Logger object at 0x7eff73ff3170>'}
2026-01-16 22:56:45,733 INFO    MainThread:51694 [sb3.py:save_model():147] [no run ID] Saving model checkpoint to ./wandb_models/model.zip
2026-01-16 23:04:27,424 INFO    MainThread:51694 [sb3.py:save_model():147] [no run ID] Saving model checkpoint to ./wandb_models/model.zip
2026-01-16 23:04:27,539 INFO    MainThread:51694 [sb3.py:save_model():147] [no run ID] Saving model checkpoint to ./wandb_models/model.zip
2026-01-16 23:04:27,608 INFO    MainThread:51694 [wandb_run.py:_finish():2287] finishing run 3297240254-bit/offroad-sac-ds/4t4ktl83
2026-01-16 23:04:27,608 INFO    MainThread:51694 [wandb_run.py:_atexit_cleanup():2486] got exitcode: 0
2026-01-16 23:04:27,609 INFO    MainThread:51694 [wandb_run.py:_restore():2468] restore
2026-01-16 23:04:27,609 INFO    MainThread:51694 [wandb_run.py:_restore():2474] restore done
2026-01-16 23:04:45,723 INFO    MainThread:51694 [wandb_run.py:_footer_sync_info():3862] logging synced files
